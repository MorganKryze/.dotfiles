#!/run/current-system/sw/bin/bash

# Opens a VS Code window in the .dotfiles project
function config() {
	cd ~/.dotfiles
	opn
}

function nix-update() {
	clear
	cat <<"EOF"
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣴⡾⢷⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣠⣤⣴⠶⠶⠾⠋⠀⠘⠿⠶⣦⣄⡀⠀⠀⣀⣤⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⣶⣤⣄⣀⣀⣤⡶⠟⠋⠉⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠻⢶⣼⣿⡭⢍⢿⡆⠀⠀⠀⠀⠀⠀⠀
⠀⠀⣿⡄⠉⠙⠛⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣾⠇⠈⢿⠀⢸⡇⠀⠀⠀⠀⠀⠀⠀
⠀⠀⢸⣇⠀⠀⠀⢀⣤⣤⣤⡀⠀⠀⠀⠀⠀⠀⠀⠀⢀⡀⠺⠗⠂⠛⠀⠀⠀⠀⣸⡇⠀⠀⠀⠀⠀⠀⠀
⠀⠀⢈⣿⢦⠀⣴⢿⣯⢷⠸⣧⢀⣶⡄⠀⠘⢷⠟⠛⠛⠁⠀⠀⢀⣀⣠⣤⣤⣶⡟⢀⣀⡀⠀⠀⠀⠀⠀
⠀⢀⡾⠃⠀⠒⠏⠨⣿⠶⢓⣿⠀⠉⠁⠀⣀⣀⣤⣴⡶⠶⣾⣛⣻⣽⣿⣶⡾⢾⣟⠛⠛⢿⡀⠀⠀⠀⠀
⢀⣿⠁⠀⠀⠀⢀⣀⣒⣴⣾⣷⣶⣶⣿⣿⣯⣿⠿⠾⠛⠛⣿⡋⠉⠀⢿⡄⠀⠀⢻⣆⠀⠈⢿⣦⡀⠀⠀
⠹⣿⡴⠶⠟⠛⠛⠋⢉⣿⡿⠿⠛⠻⣯⠁⠀⠻⣦⡀⠀⠀⠙⣷⡀⠀⠀⢻⣆⣀⣤⣿⠶⢶⣿⣿⣿⣦⡀
⠀⠀⠀⠀⠀⠀⠀⠀⢾⡏⢻⣆⠀⠀⠙⢷⣄⣀⣨⣷⣤⣤⡶⢾⣿⣻⣿⣿⣿⣿⡿⠾⠛⠛⠛⠉⠀⣿⡇
⠀⠀⠀⠀⠀⠀⠀⠀⠈⢷⣄⠹⣷⠟⣛⣻⣯⣭⣿⠾⠿⠿⠛⠛⠋⠉⠁⠀⢀⣀⣠⣤⣤⣶⠶⠶⠿⠻⠃
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠻⣆⣿⡟⠉⠉⠀⠀⣀⢀⣀⣀⣀⣤⣤⡴⠶⠟⠛⠉⠉⠁⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠿⠟⠛⠛⠛⠛⠛⠛⠛⠉⠉⠉⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
EOF
	description "nix-update" "updates the nix flake and rebuilds the system taking the new configuration into account."

	cd $HOME/.dotfiles
	info "Updating nix flake..."
	nix flake update --impure || error "Failed to update nix flake." || return 1
	darwin-rebuild switch --flake $HOME/.dotfiles#concord --impure || error "Failed to rebuild the system." || return 1

	info "Cleaning up artifacts..."
	brew cleanup -s || error "Failed to clean up brew artifacts." || return 1
	cd -

	info "Saving the timestamp into a file..."
	date +%s >$HOME/.last-nix-update || error "Failed to save the timestamp." || return 1

	success "System has been updated."
}

function nix-update-check() {
	if [ ! -f $HOME/.last-nix-update ]; then
		warning "Last update unknown. Please run :'nix-update' to update the system."
		return 1
	fi

	local last_update=$(cat $HOME/.last-nix-update)
	local current_time=$(date +%s)
	local diff=$((current_time - last_update))

	if [ $diff -gt 604800 ]; then
		warning "Nix flake outdated. Please run :'nix-update' to update the system."
	fi
}

# List all processes using a disk
function processes-using-disk() {
	description "processes-using-disk" "lists all processes using a disk."

	local disk_name="$1"
	sudo lsof /Volumes/$disk_name || error "Failed to list processes using disk." || return 1

	success "Processes using the disk have been listed."
}

# Kill all processes using a disk
function kill-processes-using-disk() {
	description "kill-processes-using-disk" "kills all processes using a disk."

	local disk_name="$1"
	sudo lsof /Volumes/$disk_name | awk 'NR > 1 {print $2}' | sudo xargs kill || error "Failed to kill processes using disk." || return 1

	success "Processes using the disk have been killed."
}

# Disable spotlight indexing for a disk
function disable-spotlight-indexing-for-disk() {
	description "disable-spotlight-indexing-for-disk" "disables spotlight indexing for a disk."

	local disk_name="$1"
	sudo mdutil -d "/Volumes/$disk_name" || error "Failed to disable spotlight indexing for disk." || return 1
	sudo mdutil -X "/Volumes/$disk_name" || error "Failed to disable spotlight indexing for disk." || return 1

	success "Spotlight indexing has been disabled for the disk."
}

# Create a random hash
function rnd-hash() {
	description "rnd-hash" "creates a random hash."

	txt $(openssl rand -hex 6) || error "Failed to create random hash."
}

# Hash a string
function hash() {
	local string="$1"
	txt $(echo -n "$string" | shasum -a 256 | awk '{print $1}')
}

# Secured hash a string with a salt
function shash() {
	local string="$1"
	local salt=$(head -c 16 /dev/urandom | base64 | tr -d '=+/' | cut -c1-16)
	local combined="${string}${salt}"
	local hash=$(echo -n "$combined" | shasum -a 256 | awk '{print $1}')
	txt "${hash}:${salt}"
}

# Create a new SSH key pair for GitHub
function create-git-ssh-connections() {
	description "create-github-ssh-connection" "sets up a new SSH key pair for GitHub."

	source ~/.dotfiles/.env

	info "Generating SSH key..."
	ssh-keygen -t ed25519 -C "$GITHUB_EMAIL" -f ~/.ssh/git -p "" || error "Failed to generate SSH key." || return 1

	info "Starting the ssh-agent..."
	eval "$(ssh-agent -s)" || error "Failed to start the ssh-agent." || return 1

	info "Adding the SSH key to the ssh config for GitHub and GitLab..."
	echo "Host github.com
  PreferredAuthentications publickey
  IdentityFile ~/.ssh/git" >~/.ssh/config || error "Failed to write SSH config." || return 1

	echo "Host gitlab.com
  PreferredAuthentications publickey
  IdentityFile ~/.ssh/git" >>~/.ssh/config || error "Failed to write SSH config." || return 1

	info "Adding the SSH key to the ssh-agent..."
	ssh-add ~/.ssh/git || error "Failed to add SSH key to the ssh-agent." || return 1

	info "Copying the SSH key to the clipboard..."
	pbcopy <~/.ssh/git.pub || error "Failed to copy SSH key to clipboard." || return 1

	info "The SSH key has been copied to the clipboard. Please add it to your GitHub account."
	open "https://github.com/settings/keys" || error "Failed to open GitHub keys page." || return 1

	acknowledge "Insert your key in the GitHub account before continuing..."

	open "https://gitlab.com/-/user_settings/ssh_keys" || error "Failed to open GitLab keys page." || return 1

	acknowledge "Insert your key in the GitLab account before continuing..."

	success "SSH key has been set up successfully."
}

# Delete all .DS_Store files in a folder and its subdirectories
function flush() {
	description "flush" "deletes all .DS_Store files in a folder and its subdirectories."

	local folder="$1"

	if [ -z "$folder" ]; then
		error "Usage: delete_ds_store <folder>" || return 1
	fi

	if [ ! -d "$folder" ]; then
		error "Error: $folder is not a directory" || return 1
	fi

	find "$folder" -name ".DS_Store" -type f -exec rm -f {} \;
	success "All .DS_Store files in $folder and its subdirectories have been deleted."
}

# Open the superfile app
function spf() {
	export SPF_LAST_DIR="$HOME/Library/Application Support/superfile/lastdir"

	superfile "$@"

	[ ! -f "$SPF_LAST_DIR" ] || {
		. "$SPF_LAST_DIR"
		rm -f -- "$SPF_LAST_DIR" >/dev/null
	}
}

function backup-fab() {
	description "backup-fab" "creates a backup of the fab server data."

	REMOTE_USER="morgan"
	REMOTE_HOST="devinci-fablab.fr"
	REMOTE_DIR="/BACKUPS"
	LOCAL_DIR="/Users/morgan/Documents/00-local/00-storage/Backups_fablab"
	TIMESTAMP=$(date +"%Y%m%d%H%M%S")
	BACKUP_FILE="backup_dvfl_server_${TIMESTAMP}.tar.gz"

	info "Creating the backup..."
	# Compress the remote directory with sudo
	ssh ${REMOTE_USER}@${REMOTE_HOST} "sudo tar -czvf /tmp/${BACKUP_FILE} -C ${REMOTE_DIR} ." || error "Failed to create backup on remote server." || return 1

	info "Downloading the backup..."
	# Download the compressed file
	scp ${REMOTE_USER}@${REMOTE_HOST}:/tmp/${BACKUP_FILE} ${LOCAL_DIR} || error "Failed to download backup from remote server." || return 1

	info "Removing the temporary backup file from the remote server..."
	# Remove the compressed file from the remote server
	ssh ${REMOTE_USER}@${REMOTE_HOST} "sudo rm -f /tmp/${BACKUP_FILE}" || error "Failed to remove temporary backup file from remote server." || return 1

	success "Backup of the fab server data has been created and downloaded to ${LOCAL_DIR}/${BACKUP_FILE}."

}
